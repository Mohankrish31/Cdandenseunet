import os
import cv2
import torch
import lpips
import numpy as np
import pandas as pd
from tqdm import tqdm
from skimage.metrics import structural_similarity as compare_ssim
import math
# === Import your model variants ===
from models.unet import unet
from models.denseunet import denseunet
from models.cdan_unet import cdan_unet
from models.cdan_denseunet import cdan_denseunet
# === Device ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# === LPIPS ===
lpips_fn = lpips.LPIPS(net='vgg').to(device)
# === Metric Functions ===
def calculate_psnr(img1, img2):
    mse = np.mean((img1 - img2) ** 2)
    if mse == 0:
        return 100
    return 10 * math.log10(1.0 / mse)
def calculate_ssim(img1, img2):
    return np.mean([compare_ssim(img1[..., i], img2[..., i], data_range=1.0) for i in range(3)])
def calculate_ebcm(img1, img2):
    """Edge-Based Contrast Metric"""
    img1_gray = cv2.cvtColor((img1 * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    img2_gray = cv2.cvtColor((img2 * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    edges1 = cv2.Canny(img1_gray, 100, 200)
    edges2 = cv2.Canny(img2_gray, 100, 200)
    # Edge-based contrast metric (ratio of overlapping edges)
    intersection = np.logical_and(edges1 > 0, edges2 > 0).sum()
    union = np.logical_or(edges1 > 0, edges2 > 0).sum()
    if union == 0:
        return 0.0
    return intersection / union
# === Evaluation ===
def evaluate_model(model, high_dir, low_dir):
    model.eval()
    psnr_list, ssim_list, lpips_list, ebcm_list = [], [], [], []
    with torch.no_grad():
        for fname in tqdm(sorted(os.listdir(high_dir)), desc=f"Evaluating {model.__class__.__name__}"):
            high_path = os.path.join(high_dir, fname)
            low_path = os.path.join(low_dir, fname)
            high_img = cv2.cvtColor(cv2.imread(high_path), cv2.COLOR_BGR2RGB) / 255.0
            low_img = cv2.cvtColor(cv2.imread(low_path), cv2.COLOR_BGR2RGB) / 255.0
            inp_tensor = torch.tensor(low_img).permute(2, 0, 1).unsqueeze(0).float().to(device)
            output = model(inp_tensor).clamp(0, 1).cpu().squeeze(0).permute(1, 2, 0).numpy()
            psnr = calculate_psnr(output, high_img)
            ssim = calculate_ssim(output, high_img)
            ebcm = calculate_ebcm(output, high_img)
            lpips_val = lpips_fn(
                torch.tensor(output).permute(2, 0, 1).unsqueeze(0).float().to(device),
                torch.tensor(high_img).permute(2, 0, 1).unsqueeze(0).float().to(device)
            ).item()
            psnr_list.append(psnr)
            ssim_list.append(ssim)
            lpips_list.append(lpips_val)
            ebcm_list.append(ebcm)
    return np.mean(psnr_list), np.mean(ssim_list), np.mean(lpips_list), np.mean(ebcm_list)
# === Paths ===
high_dir = "/content/cvccolondbsplit/test/high"
low_dir = "/content/cvccolondbsplit/test/low"
# === Model Variants ===
model_variants = {
    "Baseline_UNet": unet(),
    "DenseUNet": denseunet(),
    "CDAN_UNet": cdan_unet(),
    "CDAN_DenseUNet": cdan_denseunet()
}
# === Run Ablation Study ===
results = []
for name, model in model_variants.items():
    model.to(device)
    psnr, ssim, lpips_val, ebcm = evaluate_model(model, high_dir, low_dir)
    results.append({"Model": name, "PSNR": psnr, "SSIM": ssim, "LPIPS": lpips_val, "EBCM": ebcm})
# === Save Results ===
df = pd.DataFrame(results)
df.to_csv("ablation_results_cdan.csv", index=False)
print("\nâœ… Ablation Study Results Saved to 'ablation_results_cdan.csv'")
print(df)
