import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import os
import numpy as np
import matplotlib.pyplot as plt
import lpips  # Make sure to install: pip install lpips
from models.cdan_denseunet import CDANDenseUNet
# ---------- Dataset ----------
class cvccolondbsplitDataset(Dataset):
    def __init__(self, low_dir, high_dir, transform=None):
        self.low_dir = low_dir
        self.high_dir = high_dir
        self.transform = transform
        self.image_names = sorted([f for f in os.listdir(low_dir) if f.lower().endswith(('.png','.jpg','.jpeg')) and os.path.exists(os.path.join(high_dir, f))])
    def __len__(self):
        return len(self.image_names)
    def __getitem__(self, idx):
        low_path = os.path.join(self.low_dir, self.image_names[idx])
        high_path = os.path.join(self.high_dir, self.image_names[idx])
        low_img = Image.open(low_path).convert("RGB")
        high_img = Image.open(high_path).convert("RGB")
        if self.transform:
            low_img = self.transform(low_img)
            high_img = self.transform(high_img)
        return low_img, high_img
# ---------- Loss utilities (use your existing functions) ----------
mse_loss_fn = nn.MSELoss()
# edge_loss_fn, ssim_loss_fn, total_loss_fn assumed identical to yours (reuse)
# lpips model:
lpips_model = lpips.LPIPS(net='vgg').to(device)
# ---------- Loss Functions ----------
def compute_losses(pred, target):
    # pred, target in [0,1]
    mse   = mse_loss_fn(pred, target)
    edge  = edge_loss_fn(pred, target)              # using your SobelEdgeLoss
    lp    = lpips_model(2*pred - 1, 2*target - 1).mean()  # lpips expects [-1,1]
    ssim  = ssim_loss_fn(pred, target)               # your SSIMLoss
    total = w_mse*mse + w_lpips*lp + w_edge*edge + w_ssim*ssim
    return total, mse, lp, edge, ssim
def plot_loss_curve(train_losses, val_losses):
    """Plot training and validation loss curves"""
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)
    plt.savefig('loss_curve.png')
    plt.show()
# ==================== TRAINING SETUP ====================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Hyperparameters (YOU NEED TO SET THESE)
learning_rate = 0.001
weight_decay = 1e-5
num_epochs = 100
early_stopping_patience = 10
batch_size = 8
# Transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])
# Paths
train_high_dir = "/content/cvccolondbsplit/train/high"
train_low_dir = "/content/cvccolondbsplit/train/low"
val_high_dir = "/content/cvccolondbsplit/val/high"
val_low_dir = "/content/cvccolondbsplit/val/low"
# Create datasets and dataloaders
train_dataset = cvccolondbsplitDataset(train_low_dir, train_high_dir, transform=transform)
val_dataset = cvccolondbsplitDataset(val_low_dir, val_high_dir, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
# Initialize model, optimizer, and LPIPS
model = CDANDenseUNet(in_channels=3, out_channels=3, base_channels=32, growth_rate=12, output_range="01").to(device)
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
lpips_model = lpips.LPIPS(net='vgg').to(device)
# Training loop
best_val_loss = float('inf')
patience_counter = 0
train_losses = []
val_losses = []
print("Starting training...")
for epoch in range(num_epochs):
    # Training
    model.train()
    running_loss = 0.0
    for input_img, target_img in train_loader:
        input_img = input_img.to(device)
        target_img = target_img.to(device)
        optimizer.zero_grad()
        pred = model(input_img)
        total_loss, mse_val, lp_val, edge_val, ssim_val = compute_losses(pred, target_img)
        total_loss.backward()
        optimizer.step()
        running_loss += total_loss.item()
    avg_train_loss = running_loss / len(train_loader)
    train_losses.append(avg_train_loss)
    # Validation
    model.eval()
    val_running = 0.0
    with torch.no_grad():
        for input_img, target_img in val_loader:
            input_img = input_img.to(device)
            target_img = target_img.to(device)
            pred = model(input_img)
            total_loss, _, _, _, _ = compute_losses(pred, target_img)
            val_running += total_loss.item()
    avg_val_loss = val_running / len(val_loader)
    val_losses.append(avg_val_loss)
    print(f"Epoch {epoch+1}/{num_epochs}  TrainLoss: {avg_train_loss:.6f}  ValLoss: {avg_val_loss:.6f}")
    # Save best model
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        patience_counter = 0
        torch.save(model.state_dict(), 'best_cdan_denseunet.pth')
        print("âœ… Saved best model.")
    else:
        patience_counter += 1
        if patience_counter >= early_stopping_patience:
            print("ðŸ›‘ Early stopping triggered")
            break
# Plot results
plot_loss_curve(train_losses, val_losses)
print("Training completed!")
